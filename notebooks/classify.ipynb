{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "import requests\n",
    "import urllib.request\n",
    "import keras\n",
    "import sklearn\n",
    "import sklearn.cross_validation\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from pathlib import Path\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = Path('../data/unclean')\n",
    "\n",
    "for page in range(2, 10):\n",
    "    r = requests.get('https://test.flaunt.peekabuy.com/api/board/get_jc_product_images_batch/?page={}'.format(page))\n",
    "    image_urls = r.json()['images']\n",
    "    for url, category, _ in image_urls:\n",
    "        splits = url.split('/')\n",
    "        filename = splits[-1]\n",
    "        filepath = data_dir / filename\n",
    "\n",
    "        if filepath.exists():\n",
    "            continue\n",
    "\n",
    "        urllib.request.urlretrieve(url, str(filepath))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# category_frame = pd.DataFrame(columns=['category', 'filename'])\n",
    "#         # update the dataframe anyways because we have to rewrite it\n",
    "#         category_frame = category_frame.append({'filename': filename,\n",
    "#                                                 'category': category}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "category_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>poo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [category, poo]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do dresses with shirts count as one thing or two things\n",
    "    - try treating as one piece\n",
    "- Should clothes with people in them be rejected\n",
    "    - \n",
    "- Should clothes with weird backgrounds (i.e. white on white) be rejected also\n",
    "    - classify them out\n",
    "    \n",
    "    \n",
    "Do fine-grained annotation but try bucketing / not bucketing the labels\n",
    "\n",
    "There's a list of labels that should be fed through the existing cropping pipeline and a list that need to be further examined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcMAAAEMCAYAAAC4ON2/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a066cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gt_labels = pd.read_csv('../data/raw.csv', header=None, names=['image_name', 'tag'])\n",
    "\n",
    "sns.countplot(data=gt_labels, y='tag')\n",
    "\n",
    "num_classes = len(gt_labels.tag.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fine-grained first pass\n",
    "\n",
    "# create directory of symlinks\n",
    "data_path = Path('../data')\n",
    "train_finegrain_dir = data_path / 'train_finegrain'\n",
    "test_finegrain_dir = data_path / 'test_finegrain'\n",
    "if not train_finegrain_dir.exists():\n",
    "    train_finegrain_dir.mkdir()\n",
    "    \n",
    "if not test_finegrain_dir.exists():\n",
    "    test_finegrain_dir.mkdir()\n",
    "\n",
    "# generate stratified split\n",
    "X = gt_labels.image_name\n",
    "y = gt_labels.tag\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(X, y, test_size=0.1, stratify=y)\n",
    "\n",
    "# symlink train data\n",
    "for im_name, label in zip(X_train, y_train):\n",
    "    source_path = (data_path / 'raw' /im_name).resolve()\n",
    "    dest_path = train_finegrain_dir / label / im_name\n",
    "    \n",
    "    class_dir = dest_path.parent\n",
    "    \n",
    "    if not class_dir.exists():\n",
    "        class_dir.mkdir()\n",
    "    \n",
    "    if dest_path.exists():\n",
    "        continue\n",
    "    \n",
    "    os.symlink(str(source_path), str(dest_path))\n",
    "    \n",
    "# symlink test data\n",
    "for im_name, label in zip(X_test, y_test):\n",
    "    source_path = (data_path / 'raw' /im_name).resolve()\n",
    "    dest_path = test_finegrain_dir / label / im_name\n",
    "    \n",
    "    class_dir = dest_path.parent\n",
    "    \n",
    "    if not class_dir.exists():\n",
    "        class_dir.mkdir()\n",
    "    \n",
    "    if dest_path.exists():\n",
    "        continue\n",
    "    \n",
    "    os.symlink(str(source_path), str(dest_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 9 classes.\n",
      "Found 10 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "# train / test generators\n",
    "train_data_dir = str(train_finegrain_dir)\n",
    "validation_data_dir = str(test_finegrain_dir)\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(3, 224, 224)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  \n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 836/2000 [===========>..................] - ETA: 172s - loss: 2.1517 - acc: 0.2368"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-71c26d3ef8e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         nb_val_samples=800)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'finegrained.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/peekabuy/projects/detect_clothes/env/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m                                         \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_val_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m                                         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m                                         max_q_size=max_q_size)\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/peekabuy/projects/detect_clothes/env/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size)\u001b[0m\n\u001b[1;32m   1411\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1412\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1413\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1414\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/peekabuy/projects/detect_clothes/env/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/peekabuy/projects/detect_clothes/env/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/peekabuy/projects/detect_clothes/env/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/peekabuy/projects/detect_clothes/env/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=2000,\n",
    "        nb_epoch=50,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=800)\n",
    "model.save_weights('finegrained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_class(path):\n",
    "    if 'clean' == str(path.parent.stem):\n",
    "        return 'clean'\n",
    "    else:\n",
    "        return 'unclean'\n",
    "\n",
    "# generate train / test split on clean and unclean data\n",
    "clean_data_path = Path('../data/clean')\n",
    "unclean_data_path = Path('../data/unclean')\n",
    "\n",
    "# generate categories\n",
    "clean_dict = [{str(p): get_class(p) for p in itertools.chain(clean_data_path.glob('*.jpg'), \n",
    "                                                       unclean_data_path.glob('*.jpg'))}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate train / test split\n",
    "clean_frame = pd.DataFrame(clean_dict).transpose()\n",
    "\n",
    "clean_frame.columns=['is_clean']\n",
    "clean_frame.index.names = ['filepath', ]\n",
    "\n",
    "# generate stratified split\n",
    "X = clean_frame.index\n",
    "y = clean_frame.is_clean\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(X, y, test_size=0.1, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_experiment_data = Path('../data/clean_experiment')\n",
    "\n",
    "if not clean_experiment_data.exists():\n",
    "    clean_experiment_data.mkdir()\n",
    "    \n",
    "clean_experiment_data = clean_experiment_data.resolve()\n",
    "\n",
    "train_data_dir = clean_experiment_data / 'train'\n",
    "if not train_data_dir.exists():\n",
    "    train_data_dir.mkdir()\n",
    "\n",
    "\n",
    "test_data_dir = clean_experiment_data / 'test'\n",
    "if not test_data_dir.exists():\n",
    "    test_data_dir.mkdir()\n",
    "\n",
    "\n",
    "# symlink train data\n",
    "for path in X_train:\n",
    "    source_path = Path(path).resolve()\n",
    "\n",
    "    label, filename = source_path.parts[-2:]\n",
    "        \n",
    "    dest_path = train_data_dir / label / filename    \n",
    "    \n",
    "    class_dir = dest_path.parent\n",
    "    \n",
    "    if not class_dir.exists():\n",
    "        class_dir.mkdir()\n",
    "    \n",
    "    if dest_path.exists():\n",
    "        continue\n",
    "            \n",
    "    os.symlink(str(source_path), str(dest_path))\n",
    "\n",
    "# symlink test data\n",
    "for path in X_test:\n",
    "    source_path = Path(path).resolve()\n",
    "\n",
    "    label, filename = source_path.parts[-2:]\n",
    "        \n",
    "    dest_path = test_data_dir / label / filename    \n",
    "    \n",
    "    class_dir = dest_path.parent\n",
    "    \n",
    "    if not class_dir.exists():\n",
    "        class_dir.mkdir()\n",
    "    \n",
    "    if dest_path.exists():\n",
    "        continue\n",
    "    \n",
    "    os.symlink(str(source_path), str(dest_path))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(3, 150, 150)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  \n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 362 images belonging to 2 classes.\n",
      "Found 41 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# train / test generators\n",
    "train_data_dir = str(train_data_dir)\n",
    "validation_data_dir = str(test_data_dir)\n",
    "\n",
    "img_height = 150\n",
    "img_width = 150\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1970/2000 [============================>.] - ETA: 2s - loss: 0.6574 - acc: 0.7142"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/projects/peekabuy/env/lib/python3.4/site-packages/keras/engine/training.py:1432: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002/2000 [==============================] - 180s - loss: 0.6535 - acc: 0.7163 - val_loss: 0.3029 - val_acc: 0.9026\n",
      "Epoch 2/50\n",
      "2012/2000 [==============================] - 175s - loss: 0.4719 - acc: 0.7982 - val_loss: 0.2423 - val_acc: 0.9260\n",
      "Epoch 3/50\n",
      "2002/2000 [==============================] - 184s - loss: 0.4199 - acc: 0.8302 - val_loss: 0.2762 - val_acc: 0.8767\n",
      "Epoch 4/50\n",
      "2012/2000 [==============================] - 196s - loss: 0.3269 - acc: 0.8603 - val_loss: 0.3177 - val_acc: 0.8533\n",
      "Epoch 5/50\n",
      "1150/2000 [================>.............] - ETA: 68s - loss: 0.3226 - acc: 0.8739"
     ]
    }
   ],
   "source": [
    "# train this \n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=2000,\n",
    "        nb_epoch=50,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=800)\n",
    "model.save_weights('clean_unclean.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- look at the filters, the performance is better than I thought\n",
    "- since it's mostly some function of average color this isn't too surprising\n",
    "\n",
    "some overfitting\n",
    "\n",
    "strong overfitting\n",
    "\n",
    "put in some weight decay or something to pump it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.patches.Rectangle at 0x13c929f60>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdEAAAJQCAYAAADRx157AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzyPLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13c1ed940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# simple bounding box doer\n",
    "test_image_filename = '7c2e0159e68207a35a8ff69238cf63ae.jpg'\n",
    "test_image_path = (Path('../data/raw') / test_image_filename).resolve()\n",
    "\n",
    "test_image = cv2.imread(str(test_image_path))\n",
    "gray_image = cv2.cvtColor(test_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def auto_canny(image, sigma=0.33):\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    " \n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    " \n",
    "    # return the edged image\n",
    "    return edged\n",
    "\n",
    "edges = auto_canny(gray_image)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(111, aspect='equal')\n",
    "ax1.imshow(edges)\n",
    "\n",
    "box = cv2.boundingRect(edges)\n",
    "\n",
    "pad = 20\n",
    "\n",
    "ax1.add_patch(\n",
    "    patches.Rectangle(\n",
    "        (box[0] - pad, box[1] - pad),   # (x,y)\n",
    "        box[2] + 2*pad,          # width\n",
    "        box[3] + 2*pad,          # height\n",
    "        fill=False\n",
    "    )\n",
    ")\n",
    "\n",
    "# im2, contours, hierarchy = cv2.findContours(edges,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_images = list(Path('../data/raw').glob('*.jpg'))\n",
    "out_dir = Path('../data/simpleboxes')\n",
    "\n",
    "if not out_dir.exists():\n",
    "    out_dir.mkdir()\n",
    "    \n",
    "pad = 5\n",
    "    \n",
    "boxes = {}\n",
    "for image_path in test_images:\n",
    "    key = image_path.parts[-1]\n",
    "    test_image = cv2.imread(str(image_path))\n",
    "    gray_image = cv2.cvtColor(test_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    edges = auto_canny(gray_image)\n",
    "    \n",
    "    x, y, w, h = cv2.boundingRect(edges)\n",
    "    \n",
    "    # draw on the image and then save it to the output place\n",
    "    \n",
    "    \n",
    "    x1 = np.clip(x - pad, 0, None)\n",
    "    y1 = np.clip(y - pad, 0, None)\n",
    "    x2 = np.clip(x + w + pad, None, test_image.shape[1])\n",
    "    y2 = np.clip(y + h + pad, None, test_image.shape[0])\n",
    "    \n",
    "    \n",
    "    cv2.rectangle(test_image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.imwrite(str(out_dir / key), test_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
