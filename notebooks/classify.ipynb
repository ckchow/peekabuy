{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peekabuy/projects/detect_clothes/env/lib/python3.5/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "import requests\n",
    "import urllib.request\n",
    "import keras\n",
    "import sklearn\n",
    "import sklearn.cross_validation\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "r = requests.get('https://test.flaunt.peekabuy.com/api/board/get_jc_product_images_batch/?page=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_urls = r.json()['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/4fbedb7bf74ebea3381a5f94ef413eac.jpg\n",
      "../data/661f7f5b758dad38ac6fdf3922c648e4.jpg\n",
      "../data/97db99ef15d57e2779b6798462023659.jpg\n",
      "../data/186d262630df3cbd68012ab89ba71e35.jpg\n",
      "../data/92c8032a9a040ad2c68dff2918f458e6.jpg\n",
      "../data/a0699e1cac5faf222ce1e8009ffae59a.jpg\n",
      "../data/5e52345a3a1fe6709eb5de229b13479c.jpg\n",
      "../data/a0e0ee65222834586338f17ce10e87eb.jpg\n",
      "../data/a6d379e60044ee743d47e6eabe35386d.jpg\n",
      "../data/80e77b7aab508f91862a11d0edd89bbc.jpg\n",
      "../data/748c6281ba693ed4f3ecc486d017dd50.jpg\n",
      "../data/93ba72bc36d1c2e0efd15fd21e910d32.jpg\n",
      "../data/530bcb6c7858f32df07301728ae49da1.jpg\n",
      "../data/f3ffb4577141d62aeb3709e6e6424c45.jpg\n",
      "../data/3d7276af693af671a3d5a2f3cc06bc0e.jpg\n",
      "../data/6165f54a8c68de1dad78db2a79e96c63.jpg\n",
      "../data/0c6fe551acc18ac002b3e8084048743c.jpg\n",
      "../data/7c2e0159e68207a35a8ff69238cf63ae.jpg\n",
      "../data/5664037d3669fbcb93aee4d03942e3dd.jpg\n",
      "../data/39bf523d1eb84d6ece22e481cc32edc3.jpg\n",
      "../data/f121e9ac236e0e12b515b8e0d4b3de62.jpg\n",
      "../data/5b6191cd14ac7a09f5b924a72958d91c.jpg\n",
      "../data/a5b5bd10c8e71f6af8d80e626b7e49a8.jpg\n",
      "../data/1b762f7ac267b9a412a27bdb9d1ffd86.jpg\n",
      "../data/58109c089ba233aa0cad57ea5609ccb9.jpg\n",
      "../data/d6b99d18034fbb0fec1a90307bf2e94a.jpg\n",
      "../data/4b96ecd15d8e19bc0dfe55d83cbe3639.jpg\n",
      "../data/378cc520d6da4ee4fcce88f0636d2dff.jpg\n",
      "../data/9f251604ffd50e32e6c46c5d84a713ce.jpg\n",
      "../data/186136c1c061fdf7e1ff2f07a0886e69.jpg\n",
      "../data/06a23592e3b0ad3ff108f1d108ff1b79.jpg\n",
      "../data/4920a36ab2c0b02e383ea6bee7557c6a.jpg\n",
      "../data/8ecbc951da754609911551f18986f919.jpg\n",
      "../data/824fe0e63671a156a84b1413b0a21db8.jpg\n",
      "../data/de8ca4ef863ad95dd717c15e4ac84c08.jpg\n",
      "../data/1470258f902cbdec8c21e7bb561f5212.jpg\n",
      "../data/8c6798b6244106a86734ad59617b50f9.jpg\n",
      "../data/ef0a614c6229e3b9d49d10dc4382554a.jpg\n",
      "../data/425608a21ed8ac71cd15abfcc104b2ed.jpg\n",
      "../data/742c54d6efe5464a86302b55a3df0040.jpg\n",
      "../data/e6cff5d2bdafddac0eed6b17b831c251.jpg\n",
      "../data/6c76f03a0b225a111876210c5dd52f1b.jpg\n",
      "../data/32d8b6c6d10e67b01230db4168cc99e0.jpg\n",
      "../data/b7b4c85382296e83ab1e0950124d15a6.jpg\n",
      "../data/a20fa0e237ee5c5abbb71ea4b290221b.jpg\n",
      "../data/f91c7005d4b68b141dd7840b0c8de987.jpg\n",
      "../data/6bd0ccf09e70e46b0b2434978a542368.jpg\n",
      "../data/f6b7b7e44b10fc3c405b0859cb4091d3.jpg\n",
      "../data/64ad883f1f99e3c86cd6d8605ee76927.jpg\n",
      "../data/0be0df16a1edfbf39918a1feb6fb2e94.jpg\n",
      "../data/3b87c16695dad40c007e38b778b027f1.jpg\n",
      "../data/b1f60a0cdc48c6dfd234aef9f3900a91.jpg\n",
      "../data/3961c5d9a9c36c7088d5f30227e807f0.jpg\n",
      "../data/896d301e82357e55b8b7b7d2e74e83c4.jpg\n",
      "../data/b65f1b48d4264c253b78f4814cab985b.jpg\n",
      "../data/f4443e6053e61b9d20ae8e3b4885e447.jpg\n",
      "../data/cdd81b646b5cc219107b1550aaf000cc.jpg\n",
      "../data/57935cc267d118276894667d0ae2880f.jpg\n",
      "../data/eff2c1eee1f6f1d951f6cf1c7d972999.jpg\n",
      "../data/2acd6ca1638b189b3b9e25c9a17837b6.jpg\n",
      "../data/aeea378590a472b042f5679bff08ec45.jpg\n",
      "../data/794a933a6ce5a63a0ed4ed07bd79a7ea.jpg\n",
      "../data/fbd1fdd1b62e68e386f44320901a37a4.jpg\n",
      "../data/6840e56fc196ae2e0f47d4e880ac4cd8.jpg\n",
      "../data/a70fa63e3ed4e3cfb772492039f85074.jpg\n",
      "../data/d29f6cb30d043bb35f4178159420e1c5.jpg\n",
      "../data/48ae618e6d98bce7818c1feab394d8d7.jpg\n",
      "../data/8ac729a874634125cda60c19f42f365a.jpg\n",
      "../data/7a4758061fc15fe93a4870eff52e8cd1.jpg\n",
      "../data/26ae75b2e858280949de8e5cb47eaa0b.jpg\n",
      "../data/6a2d26042be0df983ee5e4736a38e569.jpg\n",
      "../data/e01a49e3b2c0e486bc52c1a7ece805fc.jpg\n",
      "../data/425106d0da1be1933595d56286ea4e08.jpg\n",
      "../data/c73660712ed768d7a3f8da980b1fa3e6.jpg\n",
      "../data/a20481e34042377107d527096cdc7b17.jpg\n",
      "../data/ceaddfedaa66fe7c6de8d64bddf64128.jpg\n",
      "../data/c319c4923b8402a82e30bc6c55db55c3.jpg\n",
      "../data/c5d6af0c6b8e93f71c061e47833b0304.jpg\n",
      "../data/9d8ea254c9c548415542bd471b6dbe5f.jpg\n",
      "../data/d9437bc5b7bd53c2c740da8e2533b872.jpg\n",
      "../data/18a0a97858de95dd07d02986510768dc.jpg\n",
      "../data/b58b3bde9016b37849f20ff797898ed4.jpg\n",
      "../data/0d0d730340223a0d4db03d232e85d452.jpg\n",
      "../data/996c8a6c5e9e7be85e29447b2452878f.jpg\n",
      "../data/efc992823d3aa126faea5b1e88b67fc7.jpg\n",
      "../data/200a89c568ee679a94fce6c53aaaf1c7.jpg\n",
      "../data/9f280a181c4a92a1294610fd551dcf4a.jpg\n",
      "../data/db35853793eb5b0283adcf3b986b9051.jpg\n",
      "../data/4f2899a025a8ebc6230d0ee593103d66.jpg\n",
      "../data/08728fbfbc0bae010631ea76ccc938ff.jpg\n",
      "../data/cee51f7c2c6f9510a9952c461f2aaa28.jpg\n",
      "../data/e1172b57a93aef17b0014999c8867a42.jpg\n",
      "../data/9c29851afe53b87ffe7d01fd4b3c8109.jpg\n",
      "../data/98e13fff832ab3a4e699117e1e56c709.jpg\n",
      "../data/41e3c3332e555849f699d9a45abb6582.jpg\n",
      "../data/36a35cd3c2f71d051a3322ed92d6e9fc.jpg\n",
      "../data/3c656c537b35b8baef4a9081aedc2908.jpg\n",
      "../data/c3cd1e612a948db03e95be6627b89b3a.jpg\n",
      "../data/a94cd4aec21680c34167ef205f05fa1a.jpg\n",
      "../data/6a5c10331b4e3d2bbc65df9abd0029e7.jpg\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path('../data/raw')\n",
    "\n",
    "for url in image_urls:\n",
    "    splits = url.split('/')\n",
    "    filename = splits[-1]\n",
    "    filepath = data_dir / filename\n",
    "    urllib.request.urlretrieve(url, str(filepath))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do dresses with shirts count as one thing or two things\n",
    "    - try treating as one piece\n",
    "- Should clothes with people in them be rejected\n",
    "    - \n",
    "- Should clothes with weird backgrounds (i.e. white on white) be rejected also\n",
    "    - classify them out\n",
    "    \n",
    "    \n",
    "Do fine-grained annotation but try bucketing / not bucketing the labels\n",
    "\n",
    "There's a list of labels that should be fed through the existing cropping pipeline and a list that need to be further examined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcMAAAEMCAYAAAC4ON2/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a066cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gt_labels = pd.read_csv('../data/raw.csv', header=None, names=['image_name', 'tag'])\n",
    "\n",
    "sns.countplot(data=gt_labels, y='tag')\n",
    "\n",
    "num_classes = len(gt_labels.tag.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fine-grained first pass\n",
    "\n",
    "# create directory of symlinks\n",
    "data_path = Path('../data')\n",
    "train_finegrain_dir = data_path / 'train_finegrain'\n",
    "test_finegrain_dir = data_path / 'test_finegrain'\n",
    "if not train_finegrain_dir.exists():\n",
    "    train_finegrain_dir.mkdir()\n",
    "    \n",
    "if not test_finegrain_dir.exists():\n",
    "    test_finegrain_dir.mkdir()\n",
    "\n",
    "# generate stratified split\n",
    "X = gt_labels.image_name\n",
    "y = gt_labels.tag\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(X, y, test_size=0.1, stratify=y)\n",
    "\n",
    "# symlink train data\n",
    "for im_name, label in zip(X_train, y_train):\n",
    "    source_path = (data_path / 'raw' /im_name).resolve()\n",
    "    dest_path = train_finegrain_dir / label / im_name\n",
    "    \n",
    "    class_dir = dest_path.parent\n",
    "    \n",
    "    if not class_dir.exists():\n",
    "        class_dir.mkdir()\n",
    "    \n",
    "    if dest_path.exists():\n",
    "        continue\n",
    "    \n",
    "    os.symlink(str(source_path), str(dest_path))\n",
    "    \n",
    "# symlink test data\n",
    "for im_name, label in zip(X_test, y_test):\n",
    "    source_path = (data_path / 'raw' /im_name).resolve()\n",
    "    dest_path = test_finegrain_dir / label / im_name\n",
    "    \n",
    "    class_dir = dest_path.parent\n",
    "    \n",
    "    if not class_dir.exists():\n",
    "        class_dir.mkdir()\n",
    "    \n",
    "    if dest_path.exists():\n",
    "        continue\n",
    "    \n",
    "    os.symlink(str(source_path), str(dest_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 9 classes.\n",
      "Found 10 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# train / test generators\n",
    "train_data_dir = str(train_finegrain_dir)\n",
    "validation_data_dir = str(test_finegrain_dir)\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(3, 224, 224)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  \n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/peekabuy/projects/detect_clothes/env/lib/python3.5/site-packages/keras/engine/training.py\", line 416, in data_generator_task\n",
      "    generator_output = next(generator)\n",
      "  File \"/Users/peekabuy/projects/detect_clothes/env/lib/python3.5/site-packages/keras/preprocessing/image.py\", line 442, in __next__\n",
      "    return self.next(*args, **kwargs)\n",
      "  File \"/Users/peekabuy/projects/detect_clothes/env/lib/python3.5/site-packages/keras/preprocessing/image.py\", line 580, in next\n",
      "    img = load_img(os.path.join(self.directory, fname), grayscale=grayscale, target_size=self.target_size)\n",
      "  File \"/Users/peekabuy/projects/detect_clothes/env/lib/python3.5/site-packages/keras/preprocessing/image.py\", line 158, in load_img\n",
      "    from PIL import Image\n",
      "ImportError: No module named 'PIL'\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-71c26d3ef8e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         nb_val_samples=800)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'finegrained.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/peekabuy/projects/detect_clothes/env/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m                                         \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_val_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m                                         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m                                         max_q_size=max_q_size)\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/peekabuy/projects/detect_clothes/env/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size)\u001b[0m\n\u001b[1;32m   1385\u001b[0m                     raise Exception('output of generator should be a tuple '\n\u001b[1;32m   1386\u001b[0m                                     \u001b[0;34m'(x, y, sample_weight) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1387\u001b[0;31m                                     'or (x, y). Found: ' + str(generator_output))\n\u001b[0m\u001b[1;32m   1388\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=2000,\n",
    "        nb_epoch=50,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=800)\n",
    "model.save_weights('finegrained.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
